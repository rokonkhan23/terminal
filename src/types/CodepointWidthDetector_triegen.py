import datetime
import io
import math
import sys
import time
import urllib.request
import zipfile
from enum import Enum
from functools import reduce
from xml.etree import ElementTree


class ClusterBreak(Enum):
    OTHER = 0
    CONTROL = 1
    EXTEND = 2
    PREPEND = 3
    ZERO_WIDTH_JOINER = 4
    REGIONAL_INDICATOR = 5
    HANGUL_L = 6
    HANGUL_V = 7
    HANGUL_T = 8
    HANGUL_LV = 9
    HANGUL_LVT = 10
    CONJUNCT_LINKER = 11
    EXTENDED_PICTOGRAPHIC = 12


class CharacterWidth(Enum):
    ZeroWidth = 0
    Narrow = 1
    Wide = 2
    Ambiguous = 3


def main():
    match len(sys.argv):
        case 1:
            ucd_url = "https://www.unicode.org/Public/UCD/latest/ucdxml/ucd.nounihan.grouped.zip"
            with urllib.request.urlopen(ucd_url) as r:
                with zipfile.ZipFile(io.BytesIO(r.read())) as z:
                    with z.open("ucd.nounihan.grouped.xml") as f:
                        source = io.BytesIO(f.read())
        case 2:
            source = sys.argv[1]
        case _:
            print("CodepointWidthDetector_triegen.py <path to ucd.nounihan.grouped.xml>")
            exit(1)

    root = ElementTree.parse(source).getroot()
    values = parse_ucd(root)

    stage2_block_size = 4
    stage3_block_size = 4
    stage4_block_size = 4

    stage1_shift = stage2_block_size + stage3_block_size + stage4_block_size
    stage2_shift = stage3_block_size + stage4_block_size
    stage3_shift = stage4_block_size

    stage2_mask = 2 ** stage2_block_size - 1
    stage3_mask = 2 ** stage3_block_size - 1
    stage4_mask = 2 ** stage4_block_size - 1

    stages = build_trie(values, [4, 4, 4])
    stage_sizes = list(map(list_value_size, stages))

    # Sanity test
    for cp, expected in enumerate(values):
        s1 = stages[0][cp >> stage1_shift]
        s2 = stages[1][s1 + ((cp >> stage2_shift) & stage2_mask)]
        s3 = stages[2][s2 + ((cp >> stage3_shift) & stage3_mask)]
        s4 = stages[3][s3 + (cp & stage4_mask)]
        assert s4 == expected

    timestamp = datetime.datetime.utcnow().isoformat(timespec='seconds')
    ucd_version = root.find("./ns:description", {"ns": "http://www.unicode.org/ns/2003/ucd/1.0"}).text
    total_size = len(ClusterBreak) ** 2 + reduce(lambda s, t: s + len(t[0]) * t[1], zip(stages, stage_sizes), 0)
    join_rules = "\n".join("    " + " ".join(f"{b:d}," for b in lead) for lead in build_join_rules())

    print(f"""// Generated by CodepointWidthDetector_triegen.py
// on {timestamp}Z from {ucd_version}
// {total_size} bytes
// clang-format off
static constexpr uint{8 * stage_sizes[0]}_t s_stage1[] = {{
{format_hex_table(stages[0], stage_sizes[0], 4, 16)}
}};
static constexpr uint{8 * stage_sizes[1]}_t s_stage2[] = {{
{format_hex_table(stages[1], stage_sizes[1], 4, 2 ** stage2_block_size)}
}};
static constexpr uint{8 * stage_sizes[2]}_t s_stage3[] = {{
{format_hex_table(stages[2], stage_sizes[2], 4, 2 ** stage3_block_size)}
}};
static constexpr uint{8 * stage_sizes[3]}_t s_stage4[] = {{
{format_hex_table(stages[3], stage_sizes[3], 4, 2 ** stage4_block_size)}
}};
static constexpr uint8_t s_joinRules[{len(ClusterBreak)}][{len(ClusterBreak)}] = {{
{join_rules}
}};
[[msvc::forceinline]] constexpr uint{8 * stage_sizes[3]}_t ucdLookup(const char32_t cp) noexcept
{{
    const auto s1 = s_stage1[cp >> {stage1_shift}];
    const auto s2 = s_stage2[s1 + ((cp >> {stage2_shift}) & {stage2_mask})];
    const auto s3 = s_stage3[s2 + ((cp >> {stage3_shift}) & {stage3_mask})];
    const auto s4 = s_stage4[s3 + (cp & {stage4_mask})];
    return s4;
}}
[[msvc::forceinline]] constexpr uint8_t ucdGraphemeJoins(const uint8_t lead, const uint8_t trail) noexcept
{{
    const auto l = lead & 15;
    const auto t = trail & 15;
    return s_joinRules[l][t];
}}
[[msvc::forceinline]] constexpr int ucdToCharacterWidth(const uint8_t val) noexcept
{{
    return val >> 6;
}}
// clang-format on""")


def parse_ucd(root: ElementTree):
    initial_value = build_trie_value(ClusterBreak.OTHER, CharacterWidth.Narrow)
    values = [initial_value] * 1114112

    tags = {}

    for group in root.findall("./ns:repertoire/ns:group", {"ns": "http://www.unicode.org/ns/2003/ucd/1.0"}):
        group_gc = group.get("gc")  # general category
        group_gcb = group.get("GCB")  # grapheme cluster break
        group_incb = group.get("InCB")  # indic conjunct break
        group_extpict = group.get("ExtPict")  # extended pictographic
        group_ea = group.get("ea")  # east-asian (width)

        for char in group:
            char_gc = char.get("gc") or group_gc
            char_gcb = char.get("GCB") or group_gcb
            char_incb = char.get("InCB") or group_incb
            char_extpict = char.get("ExtPict") or group_extpict
            char_ea = char.get("ea") or group_ea

            if char.tag not in tags:
                tags[char.tag] = True
                print(char.tag)

            # <reserved cp="2065" age="unassigned" na="" gc="Cn" bc="BN" lb="XX" sc="Zzzz" scx="Zzzz" DI="Y" ODI="Y" Gr_Base="N" Pat_Syn="N" GCB="CN" CWKCF="Y" NFKC_CF="" vo="U" NFKC_SCF=""/>

            match char_gcb:
                case "XX":  # Anything else
                    cb = ClusterBreak.OTHER
                case "CR" | "LF" | "CN":  # Carriage Return, Line Feed, Control
                    # We ignore GB3 which demands that CR Ã— LF do not break apart, because
                    # a) these control characters won't normally reach our text storage
                    # b) otherwise we're in a raw write mode and historically conhost stores them in separate cells
                    cb = ClusterBreak.CONTROL
                case "EX" | "SM":  # Extend, SpacingMark
                    cb = ClusterBreak.EXTEND
                case "PP":  # Prepend
                    cb = ClusterBreak.PREPEND
                case "ZWJ":  # Zero Width Joiner
                    cb = ClusterBreak.ZERO_WIDTH_JOINER
                case "RI":  # Regional Indicator
                    cb = ClusterBreak.REGIONAL_INDICATOR
                case "L":  # Hangul Syllable Type L
                    cb = ClusterBreak.HANGUL_L
                case "V":  # Hangul Syllable Type V
                    cb = ClusterBreak.HANGUL_V
                case "T":  # Hangul Syllable Type T
                    cb = ClusterBreak.HANGUL_T
                case "LV":  # Hangul Syllable Type LV
                    cb = ClusterBreak.HANGUL_LV
                case "LVT":  # Hangul Syllable Type LVT
                    cb = ClusterBreak.HANGUL_LVT
                case _:
                    raise RuntimeError(f"unrecognized GCB: {char_gcb}")

            if char_extpict == "Y":
                # Currently every single Extended_Pictographic codepoint happens to be GCB=XX.
                # This is fantastic for us because it means we can stuff it into the ClusterBreak enum
                # and treat it as an alias of EXTEND, but with the special GB11 properties.
                assert cb == ClusterBreak.OTHER
                cb = ClusterBreak.EXTENDED_PICTOGRAPHIC

            if char_incb == "Linker":
                # Similarly here, we can treat it as an alias for EXTEND, but with the GB9c properties.
                assert cb == ClusterBreak.EXTEND
                cb = ClusterBreak.CONJUNCT_LINKER

            match char_ea:
                case "N" | "Na" | "H":  # neutral, narrow, half-width
                    width = CharacterWidth.Narrow
                case "F" | "W":  # full-width, wide
                    width = CharacterWidth.Wide
                case "A":  # ambiguous
                    width = CharacterWidth.Ambiguous
                case _:
                    raise RuntimeError(f"unrecognized ea: {char_ea}")

            # There's no "ea" attribute for "zero width" so we need to do that ourselves. This matches:
            #   Mc: Mark, spacing combining
            #   Me: Mark, enclosing
            #   Mn: Mark, non-spacing
            #   Cf: Control, format
            if char_gc.startswith("M") or char_gc == "Cf":
                width = CharacterWidth.ZeroWidth

            value = build_trie_value(cb, width)
            if value == initial_value:
                continue

            cp = char.get("cp")  # codepoint
            if cp is not None:
                cp = int(cp, 16)
                set_range_inclusive(values, cp, cp, value)
            else:
                cp_first = int(char.get("first-cp"), 16)
                cp_last = int(char.get("last-cp"), 16)
                set_range_inclusive(values, cp_first, cp_last, value)

    # For the following ranges to be narrow, because we're a terminal:
    # box-drawing and block elements require 1-cell alignment
    set_range_inclusive(values, 0x2500, 0x259F, build_trie_value(ClusterBreak.OTHER, CharacterWidth.Narrow))
    # hexagrams are historically narrow
    set_range_inclusive(values, 0x4DC0, 0x4DFF, build_trie_value(ClusterBreak.OTHER, CharacterWidth.Narrow))
    # narrow combining ligatures (split into left/right halves, which take 2 columns together)
    set_range_inclusive(values, 0xFE20, 0xFE2F, build_trie_value(ClusterBreak.OTHER, CharacterWidth.Narrow))

    return values


def build_join_rules():
    # UAX #29 states:
    # > Note: Testing two adjacent characters is insufficient for determining a boundary.
    #
    # I completely agree, but I really hate it. So this code trades off correctness for simplicity
    # by using a simple lookup table anyway. Under most circumstances users won't notice,
    # because as far as I can see this only behaves different for degenerate ("invalid") Unicode.
    # It reduces our code complexity significantly and is way *way* faster.
    #
    # This is a great reference for the resulting table:
    #   https://www.unicode.org/Public/UCD/latest/ucd/auxiliary/GraphemeBreakTest.html

    # NOTE: We build the table in reverse, because rules with lower numbers take priority.
    # (This is primarily relevant for GB9b vs. GB4.)

    # Otherwise, break everywhere.
    # GB999: Any Ã· Any
    rules = [[False] * len(ClusterBreak) for _ in range(len(ClusterBreak))]

    # Do not break within emoji flag sequences. That is, do not break between regional indicator
    # (RI) symbols if there is an odd number of RI characters before the break point.
    # GB13: [^RI] (RI RI)* RI Ã— RI
    # GB12: sot (RI RI)* RI Ã— RI
    #
    # We cheat here by not checking that the number of RIs is even. Meh!
    rules[ClusterBreak.REGIONAL_INDICATOR.value][ClusterBreak.REGIONAL_INDICATOR.value] = True

    # Do not break within emoji modifier sequences or emoji zwj sequences.
    # GB11: \p{Extended_Pictographic} Extend* ZWJ Ã— \p{Extended_Pictographic}
    #
    # We cheat here by not checking that the ZWJ is preceded by an ExtPic. Meh!
    rules[ClusterBreak.ZERO_WIDTH_JOINER.value][ClusterBreak.EXTENDED_PICTOGRAPHIC.value] = True

    # Do not break within certain combinations with Indic_Conjunct_Break (InCB)=Linker.
    # GB9c: \p{InCB=Consonant} [\p{InCB=Extend}\p{InCB=Linker}]* \p{InCB=Linker} [\p{InCB=Extend}\p{InCB=Linker}]* Ã— \p{InCB=Consonant}
    #
    # I'm sure GB9c is great for these languages, but honestly the definition is complete whack.
    # Just look at that chonker! This isn't a "cheat" like the others above, this is a reinvention:
    # We treat it as having both ClusterBreak.PREPEND and ClusterBreak.EXTEND properties.
    fill_range(rules[ClusterBreak.CONJUNCT_LINKER.value], True)
    for lead in rules:
        lead[ClusterBreak.CONJUNCT_LINKER.value] = True

    # Do not break before SpacingMarks, or after Prepend characters.
    # GB9b: Prepend Ã—
    fill_range(rules[ClusterBreak.PREPEND.value], True)

    # Do not break before SpacingMarks, or after Prepend characters.
    # GB9a: Ã— SpacingMark
    # Do not break before extending characters or ZWJ.
    # GB9: Ã— (Extend | ZWJ)
    for lead in rules:
        # CodepointWidthDetector_triegen.py sets SpacingMarks to ClusterBreak.EXTEND as well,
        # since they're entirely identical to GB9's Extend.
        lead[ClusterBreak.EXTEND.value] = True
        lead[ClusterBreak.ZERO_WIDTH_JOINER.value] = True

    # Do not break Hangul syllable sequences.
    # GB8: (LVT | T) x T
    rules[ClusterBreak.HANGUL_LVT.value][ClusterBreak.HANGUL_T.value] = True
    rules[ClusterBreak.HANGUL_T.value][ClusterBreak.HANGUL_T.value] = True
    # GB7: (LV | V) x (V | T)
    rules[ClusterBreak.HANGUL_LV.value][ClusterBreak.HANGUL_T.value] = True
    rules[ClusterBreak.HANGUL_LV.value][ClusterBreak.HANGUL_V.value] = True
    rules[ClusterBreak.HANGUL_V.value][ClusterBreak.HANGUL_V.value] = True
    rules[ClusterBreak.HANGUL_V.value][ClusterBreak.HANGUL_T.value] = True
    # GB6: L x (L | V | LV | LVT)
    rules[ClusterBreak.HANGUL_L.value][ClusterBreak.HANGUL_L.value] = True
    rules[ClusterBreak.HANGUL_L.value][ClusterBreak.HANGUL_V.value] = True
    rules[ClusterBreak.HANGUL_L.value][ClusterBreak.HANGUL_LV.value] = True
    rules[ClusterBreak.HANGUL_L.value][ClusterBreak.HANGUL_LVT.value] = True

    # Do not break between a CR and LF. Otherwise, break before and after controls.
    # GB5: Ã· (Control | CR | LF)
    for lead in rules:
        lead[ClusterBreak.CONTROL.value] = False
    # GB4: (Control | CR | LF) Ã·
    fill_range(rules[ClusterBreak.CONTROL.value], False)

    # We ignore GB3 which demands that CR Ã— LF do not break apart, because
    # a) these control characters won't normally reach our text storage
    # b) otherwise we're in a raw write mode and historically conhost stores them in separate cells

    # We also ignore GB1 and GB2 which demand breaks at the start and end,
    # because that's not part of the loops in GraphemeNext/Prev and not this table.
    return rules


def build_trie_value(cb: ClusterBreak, width: CharacterWidth) -> int:
    return cb.value | (width.value << 6)


def chunked(lst: iter, n: int):
    for i in range(0, len(lst), n):
        yield lst[i:i + n]


def set_range_inclusive(lst: iter, beg: int, end: int, value: any):
    for i in range(beg, end + 1):
        lst[i] = value


def fill_range(lst: iter, value: any):
    for i in range(len(lst)):
        lst[i] = value


def build_trie(values: iter, stage_shifts: [int]):
    stages = []

    for shift in stage_shifts:
        chunk_size = 2 ** shift
        cache = {}
        offsets = []
        dedup_chunks = []

        for chunk in chunked(values, chunk_size):
            chunk_id = ",".join(map(str, chunk))
            if chunk_id not in cache:
                cache[chunk_id] = len(dedup_chunks)
                dedup_chunks.extend(chunk)
            offsets.append(cache[chunk_id])

        stages.append(dedup_chunks)
        values = offsets

    stages.append(values)
    stages.reverse()
    return stages


def list_value_size(lst: iter):
    return math.ceil(math.log2(max(lst) + 1) / 8)


def format_hex_table(lst: iter, byte_size: int, indent: int, width: int):
    f = f"0x{{:0{2 * byte_size}x}}"
    s = ""
    for chunk in chunked(lst, width):
        if len(s) != 0:
            s += ",\n"
        s += " " * indent
        s += ", ".join(f.format(c) for c in chunk)
    return s


if __name__ == '__main__':
    main()
